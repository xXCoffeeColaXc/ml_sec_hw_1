{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'ml_sec_hw_data/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_binary_loader(bytes, s):\n",
    "    l = len(bytes)\n",
    "    print(\"bytes length: \", l)\n",
    "\n",
    "    if l == s:\n",
    "        # Ha a fájl mérete pontosan s\n",
    "        x = bytes\n",
    "    elif l < s:\n",
    "        # Ha a fájl mérete kisebb mint s, hozzáadunk nullás paddingot\n",
    "        x = np.pad(bytes, (0, s - l), 'constant', constant_values=(0,))\n",
    "    else:\n",
    "        # Ha a fájl mérete nagyobb mint s, átlagoljuk a bájtokat\n",
    "        group_size = np.ceil(l / s) # csoportok számának kiszámítása\n",
    "        print(\"group size: \", group_size)\n",
    "        # Először hozzáadunk szükséges paddingot\n",
    "        padding_length = s * group_size - l \n",
    "        print(\"padding length: \", padding_length)\n",
    "        padded_bytes = np.pad(bytes, (0, int(padding_length)), 'constant', constant_values=(0,))\n",
    "        print(\"padding bytes: \", padded_bytes)\n",
    "        # Átlagolás\n",
    "        reshaped_bytes = padded_bytes.reshape(-1, int(group_size))\n",
    "        print(\"reshaped bytes: \\n\", reshaped_bytes)\n",
    "        x = np.mean(reshaped_bytes, axis=1)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes length:  4\n",
      "group size:  2.0\n",
      "padding length:  2.0\n",
      "padding bytes:  [1 2 3 4 0 0]\n",
      "reshaped bytes: \n",
      " [[1 2]\n",
      " [3 4]\n",
      " [0 0]]\n",
      "(3,)\n",
      "[1.5 3.5 0. ]\n"
     ]
    }
   ],
   "source": [
    "x = test_binary_loader([1,2,3,4], 3)\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5000, 3.5000, 0.0000], dtype=torch.float64)\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor_x = torch.tensor(x)\n",
    "print(tensor_x)\n",
    "\n",
    "tensor_x = tensor_x.unsqueeze(0)\n",
    "print(tensor_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    return 'malware' if label == 1 else 'benign'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. feladat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalwareDataset(Dataset):\n",
    "    def __init__(self, data_folder, s=2**14):\n",
    "        self.data_folder = data_folder\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for label in os.listdir(data_folder): # data/.../train -> malware, benign\n",
    "            for file in os.listdir(os.path.join(data_folder, label)):\n",
    "                file_path = os.path.join(data_folder, label, file)\n",
    "                x = self.preprocess_binary_file(file_path, s)\n",
    "                self.data.append(x)\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def preprocess_binary_file(self, file_path, s):\n",
    "        # Bináris fájl beolvasása\n",
    "        with open(file_path, 'rb') as file:\n",
    "            file_bytes = np.fromfile(file, dtype=np.uint8)\n",
    "\n",
    "        l = len(file_bytes)\n",
    "\n",
    "        if l == s:\n",
    "            # Ha a fájl mérete pontosan s\n",
    "            x = file_bytes\n",
    "        elif l < s:\n",
    "            # Ha a fájl mérete kisebb mint s, hozzáadunk nullás paddingot\n",
    "            x = np.pad(file_bytes, (0, s - l), 'constant', constant_values=(0,))\n",
    "        else:\n",
    "            # Ha a fájl mérete nagyobb mint s, átlagoljuk a bájtokat\n",
    "            # Először hozzáadunk szükséges paddingot\n",
    "            padding_length = s * np.ceil(l / s) - l\n",
    "            padded_bytes = np.pad(file_bytes, (0, int(padding_length)), 'constant', constant_values=(0,))\n",
    "            # Átlagolás\n",
    "            x = np.mean(padded_bytes.reshape(-1, int(np.ceil(l / s))), axis=1)\n",
    "\n",
    "        # Normalizálás [0, 1] tartományba\n",
    "        x_normalized = x / 255\n",
    "\n",
    "        return x_normalized\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx]), torch.tensor([1 if self.labels[idx] == 'malware' else 0])\n",
    "    \n",
    "def get_loader(data_folder, batch_size=32):\n",
    "    dataset = MalwareDataset(data_folder)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loader(os.path.join(data_folder, 'train'), 32)\n",
    "test_loader = get_loader(os.path.join(data_folder, 'test'), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 16384])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "data, label = next(iter(train_loader))\n",
    "print(data.unsqueeze(1).float().shape)\n",
    "print(label.float().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalwareDetector(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=10, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "        )\n",
    "        self.linear = nn.Linear(in_features=130976, out_features=1, bias=True)\n",
    "        self.out = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = x.view(x.size(0), -1) # Flatten\n",
    "        x = self.linear(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.08100762218236923\n",
      "Epoch 2/10, Loss: 0.09087397903203964\n",
      "Epoch 3/10, Loss: 0.048470813781023026\n",
      "Epoch 4/10, Loss: 0.010208791121840477\n",
      "Epoch 5/10, Loss: 0.008536127395927906\n",
      "Epoch 6/10, Loss: 0.0025879652239382267\n",
      "Epoch 7/10, Loss: 0.0028361340519040823\n",
      "Epoch 8/10, Loss: 0.0002914437500294298\n",
      "Epoch 9/10, Loss: 0.0005276032024994493\n",
      "Epoch 10/10, Loss: 0.0007692635990679264\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MalwareDetector().to(device)\n",
    "bce = nn.BCELoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model.to(device)\n",
    "\n",
    "def train(model, train_loader, opt, loss_fn, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        for data, labels in train_loader:\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            out = model(data.unsqueeze(1).float())\n",
    "            loss = loss_fn(out, labels.float())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n",
    "\n",
    "train(model, train_loader, opt, bce, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9974358974358974\n",
      "TPR: 0.9948717948717949\n",
      "TNR: 1.0\n",
      "FPR: 0.0\n",
      "FNR: 0.005128205128205128\n",
      "AUC: 0.9997633136094674\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()  # Teszt módba állítjuk a modellt\n",
    "    predictions, true_labels = [], []\n",
    "    model.to('cpu')\n",
    "    with torch.no_grad():  # Gradiensek számításának kikapcsolása\n",
    "        for data, labels in test_loader:\n",
    "            output = model(data.unsqueeze(1).float())  # Modell alkalmazása\n",
    "            pred_prob = output.squeeze().numpy()  # Valószínűségek kinyerése\n",
    "            predictions.extend(pred_prob)\n",
    "            true_labels.extend(labels.numpy())\n",
    "    \n",
    "    # Bináris osztályozási döntések (0.5 küszöbértékkel)\n",
    "    pred_labels = [1 if p >= 0.5 else 0 for p in predictions]\n",
    "    \n",
    "    # Metrikák kiszámítása\n",
    "    auc_score = roc_auc_score(true_labels, predictions)\n",
    "    tn, fp, fn, tp = confusion_matrix(true_labels, pred_labels).ravel()\n",
    "    \n",
    "    tpr = tp / (tp + fn)  # True Positive Rate\n",
    "    tnr = tn / (tn + fp)  # True Negative Rate\n",
    "    fpr = fp / (tn + fp)  # False Positive Rate\n",
    "    fnr = fn / (tp + fn)  # False Negative Rate\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)  # Átlagos pontosság\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"TPR: {tpr}\")\n",
    "    print(f\"TNR: {tnr}\")\n",
    "    print(f\"FPR: {fpr}\")\n",
    "    print(f\"FNR: {fnr}\")\n",
    "    print(f\"AUC: {auc_score}\")\n",
    "    \n",
    "    return accuracy, tpr, tnr, fpr, fnr, auc_score\n",
    "\n",
    "\n",
    "accuracy, tpr, tnr, fpr, fnr, auc = test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kérdések:\n",
    "1. Mi a betanított modell átlagos pontossága a teszt adaton ha s = 2\n",
    "14? : 99.48%\n",
    "2. Mi a modell TPR, TNR, FPR, FNR, valamint AUC értéke a teszt adaton? Mi állapítható meg ezekből a modell\n",
    "teljesítményéről? : Magas pontosság, nagyon ritkán téveszt a detektorunk. Felismeri mind a malware-t mind a benign-t. Szinte nincs félreosztályzás\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. feladat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. feladat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# malaware-hez tudunk fűzni suffix-et\n",
    "# ennek tudjuk a hosszát\n",
    "# csak titszta suffix-et tudunk változtatni\n",
    "# eretedi bináris -> preprocess -> determine_modifiable_positions -> maszk elemeivel módosítunk -> model bemenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adv_bytes:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 0, 0, 0, 0]\n",
      "bytes length:  15\n",
      "group size:  3.0\n",
      "padding length:  3.0\n",
      "padding bytes:  [ 1  2  3  4  5  6  7  8  9 10  0  0  0  0  0  0  0  0]\n",
      "reshaped bytes: \n",
      " [[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10  0  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "input:  [2.         5.         8.         3.33333333 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "original_bytes = [1,2,3,4,5,6,7,8,9,10]\n",
    "adv_suffix = [0] * 5 # ha egy csoport csakis suffix-t tartalmaz akkor a tömörített verzióban is azok lesznek, azaz módosítani tudjuk őket.\n",
    "adv_bytes = original_bytes + adv_suffix\n",
    "print(\"adv_bytes: \", adv_bytes)\n",
    "x = test_binary_loader(adv_bytes, 6)\n",
    "print(\"input: \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes length:  14\n",
      "original bytes lenght:  10\n",
      "group size:  3\n",
      "original groups:  4\n",
      "padding length:  4\n",
      "padding bytes:  [ 1  2  3  4  5  6  7  8  9 10  0  0  0  0  0  0  0  0]\n",
      "reshaped bytes: \n",
      " [[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10  0  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "padding groups:  2\n",
      "total groups:  6\n",
      "Binary length: 14, 's' value: 6, modifiable positions: set()\n",
      "bytes length:  15\n",
      "original bytes lenght:  10\n",
      "group size:  3\n",
      "original groups:  4\n",
      "padding length:  3\n",
      "padding bytes:  [ 1  2  3  4  5  6  7  8  9 10  0  0  0  0  0  0  0  0]\n",
      "reshaped bytes: \n",
      " [[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10  0  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "padding groups:  1\n",
      "total groups:  6\n",
      "5\n",
      "Binary length: 15, 's' value: 6, modifiable positions: {5}\n"
     ]
    }
   ],
   "source": [
    "def test_determine_modifiable_positions(bytes, s, suffix_length):\n",
    "    l = len(bytes)\n",
    "    modifiable_positions = set()\n",
    "    original_bytes_lenght = l-suffix_length\n",
    "    print(\"bytes length: \", l)\n",
    "    print(\"original bytes lenght: \", original_bytes_lenght)\n",
    "\n",
    "    if l >= s:\n",
    "        # Számítjuk, hány bájt kerül átlagolásra egy vektor elem létrehozásához\n",
    "        group_size = int(np.ceil(l / s))\n",
    "        \n",
    "        print(\"group size: \", group_size)\n",
    "       \n",
    "\n",
    "        # mennyi group kell az eredeti fájlhoz\n",
    "        original_groups = int(np.ceil(original_bytes_lenght / group_size))\n",
    "        print(\"original groups: \", original_groups) \n",
    "\n",
    "        # Meghatározzuk, hány bájt kerül hozzáadásra paddingként\n",
    "        padding_length = int(s * group_size - l)\n",
    "        print(\"padding length: \", padding_length)\n",
    "\n",
    "        padded_bytes = np.pad(bytes, (0, padding_length), 'constant', constant_values=(0,))\n",
    "        print(\"padding bytes: \", padded_bytes)\n",
    "        \n",
    "        reshaped_bytes = padded_bytes.reshape(-1, group_size)\n",
    "        \n",
    "        # Csoportok tartalmazhatnak: (ha márcsak egy másmilyen elem is van mint suffix, akkor az egész csoport nem módosítható)\n",
    "            # eredeti fájl csoportok\n",
    "            # (tiszta) suffix csoportok\n",
    "            # padding csoportok\n",
    "        \n",
    "        print(\"reshaped bytes: \\n\", reshaped_bytes)\n",
    "\n",
    "        # mennyi group kell az eredeti fájlhoz\n",
    "        padding_groups = int(np.ceil(padding_length / group_size))\n",
    "        print(\"padding groups: \", padding_groups) \n",
    "\n",
    "        total_length = l+padding_length\n",
    "        total_groups = int(np.ceil(total_length / group_size))\n",
    "        print(\"total groups: \", total_groups)\n",
    "\n",
    "        for i in range(original_groups+1, total_groups-padding_groups+1):\n",
    "            print(i)\n",
    "            modifiable_positions.add(i)\n",
    "\n",
    "        # # Ha a suffix hossza nagyobb, mint a szükséges padding hossza, az utolsó csoportba eső bájtok módosíthatók\n",
    "        # if suffix_length > padding_length:\n",
    "        #     modifiable_positions.add(s - 1)  # Az utolsó vektor pozíció módosítható\n",
    "    \n",
    "    return modifiable_positions\n",
    "\n",
    "# Tesztesetek a függvény ellenőrzésére\n",
    "# Példa bináris fájlok és az 's' paraméter\n",
    "binaries = [\n",
    "    ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10] + [0]*4, 6, 4),  # 4 bájt hozzáadva\n",
    "    ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10] + [0]*5, 6, 5)   # 5 bájt hozzáadva\n",
    "]\n",
    "\n",
    "# A determine_modifiable_positions függvény tesztelése\n",
    "for binary, s, suffix in binaries:\n",
    "    modifiable_positions = test_determine_modifiable_positions(np.array(binary), s, suffix)\n",
    "    print(f\"Binary length: {len(binary)}, 's' value: {s}, modifiable positions: {modifiable_positions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_modifiable_positions(binary_tensor, s, suffix_length):\n",
    "    modifiable_positions = set()\n",
    "\n",
    "    # Original binary length\n",
    "    original_binary_length = binary_tensor.shape[0]\n",
    "\n",
    "    # Attach suffix to binary\n",
    "    suffix_tensor = torch.zeros(suffix_length, dtype=binary_tensor.dtype)\n",
    "    binary_suffix = torch.cat((binary_tensor, suffix_tensor), dim=0)\n",
    "\n",
    "    l = binary_suffix.shape[0]\n",
    "    \n",
    "    if l >= s:\n",
    "        group_size = int(np.ceil(l / s))\n",
    "        \n",
    "        # How many groups are needed for the original file\n",
    "        original_groups = int(np.ceil(original_binary_length / group_size))\n",
    "\n",
    "        # Calculate the padding length needed\n",
    "        padding_length = int(s * group_size - l)\n",
    "        \n",
    "        # How many groups are needed for the padding\n",
    "        padding_groups = int(np.ceil(padding_length / group_size))\n",
    "    \n",
    "        total_length = l + padding_length\n",
    "        total_groups = int(np.ceil(total_length / group_size))\n",
    "        \n",
    "        # Identify modifiable groups\n",
    "        for i in range(original_groups + 1, total_groups - padding_groups + 1):\n",
    "            modifiable_positions.add(i)\n",
    "    \n",
    "    return modifiable_positions, len(modifiable_positions)\n",
    "\n",
    "# # Example Usage:\n",
    "# data = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=torch.float32)  # Example binary data tensor\n",
    "# s = 6  # Target vector length\n",
    "# suffix_length = 5  # Suffix length\n",
    "\n",
    "# modifiable_positions, num_modifiable_positions, modified_data = determine_modifiable_positions(data, s, suffix_length)\n",
    "# print(f\"Modifiable positions: {modifiable_positions}, \\nNumber of modifiable positions: {num_modifiable_positions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "malware_files = []\n",
    "victim_malware_path = 'ml_sec_hw_data/data/victim/malware'\n",
    "for file in os.listdir(victim_malware_path):\n",
    "    file_path = os.path.join(victim_malware_path, file)\n",
    "    with open(file_path, 'rb') as file:\n",
    "        file_bytes = np.fromfile(file, dtype=np.uint8)\n",
    "        if len(file_bytes) >= 2**14:\n",
    "            malware_files.append(file_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_binary_file(file_bytes, s):\n",
    "    l = len(file_bytes)\n",
    "    padding_length = s * np.ceil(l / s) - l\n",
    "    padded_bytes = np.pad(file_bytes, (0, int(padding_length)), 'constant', constant_values=(0,))\n",
    "    x = np.mean(padded_bytes.reshape(-1, int(np.ceil(l / s))), axis=1)\n",
    "    x_normalized = x / 255\n",
    "\n",
    "    return x_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: malware, Prob: 0.9997159838676453\n",
      "True label:  malware\n",
      "Predicted label: malware, Prob: 0.9999836683273315\n",
      "True label:  malware\n",
      "Predicted label: malware, Prob: 0.9998782873153687\n",
      "True label:  malware\n",
      "Predicted label: malware, Prob: 0.999765932559967\n",
      "True label:  malware\n",
      "Predicted label: malware, Prob: 1.0\n",
      "True label:  malware\n",
      "Predicted label: malware, Prob: 0.9988945126533508\n",
      "True label:  malware\n",
      "Predicted label: malware, Prob: 0.9024966359138489\n",
      "True label:  malware\n",
      "Predicted label: malware, Prob: 0.9998186230659485\n",
      "True label:  malware\n",
      "Predicted label: malware, Prob: 0.9997633099555969\n",
      "True label:  malware\n",
      "Predicted label: malware, Prob: 0.9999958276748657\n",
      "True label:  malware\n"
     ]
    }
   ],
   "source": [
    "s = 2**14\n",
    "for malware_file in malware_files[:10]:\n",
    "    test_input = preprocess_binary_file(malware_file, s)\n",
    "    test_input = torch.tensor(test_input)\n",
    "    test_input = test_input.unsqueeze(0).unsqueeze(1).float()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():  # Gradiensek számításának kikapcsolása\n",
    "        output = model(test_input)  # Modell alkalmazása\n",
    "        pred_prob = output.squeeze().numpy()  # Valószínűségek kinyerése\n",
    "        pred_labels = 1 if pred_prob >= 0.5 else 0\n",
    "\n",
    "    print(f\"Predicted label: {convert_label(pred_labels)}, Prob: {pred_prob}\")\n",
    "    print(\"True label: \", convert_label(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: malware, Prob: 0.9999961853027344\n",
      "True label:  malware\n",
      "Predicted label: malware, Prob: 0.9739277362823486\n",
      "True label:  malware\n",
      "Predicted label: malware, Prob: 0.9978165626525879\n",
      "True label:  malware\n",
      "Predicted label: malware, Prob: 0.9234692454338074\n",
      "True label:  malware\n",
      "Predicted label: malware, Prob: 1.0\n",
      "True label:  malware\n",
      "Predicted label: benign, Prob: 0.30393102765083313\n",
      "True label:  malware\n",
      "Predicted label: malware, Prob: 0.993300199508667\n",
      "True label:  malware\n",
      "Predicted label: malware, Prob: 0.9304697513580322\n",
      "True label:  malware\n",
      "Predicted label: malware, Prob: 0.9996460676193237\n",
      "True label:  malware\n",
      "Predicted label: malware, Prob: 1.0\n",
      "True label:  malware\n"
     ]
    }
   ],
   "source": [
    "s = 2**14\n",
    "suffix_percentage = 0.1  # 5% suffix hozzáadása\n",
    "\n",
    "for malware_file in malware_files[:10]:\n",
    "\n",
    "    binary = torch.tensor(malware_file).squeeze()\n",
    "    suffix_length = int(binary.shape[0] * suffix_percentage)\n",
    "    # Kezdetben nullákat fűzünk hozzá\n",
    "    suffix_zeros = torch.zeros(suffix_length, dtype=data.dtype)\n",
    "    modified_data = torch.cat((binary, suffix_zeros), dim=0)\n",
    "\n",
    "    # Preprocess-t megnézzük, majd kitaláljuk mely pozíciók módosíthatóak\n",
    "    modified_input = preprocess_binary_file(modified_data, 2**14)\n",
    "\n",
    "    # Most meghatározzuk, mely pozíciók módosíthatóak\n",
    "    modifiable_positions, M_len = determine_modifiable_positions(binary, s, suffix_length)\n",
    "\n",
    "    #print(modifiable_positions)\n",
    "    #print(M_len)\n",
    "\n",
    "    for pos in modifiable_positions:\n",
    "        modified_input[pos] = torch.rand(1)  # Random érték [0, 1] között\n",
    "\n",
    "    modified_input = torch.tensor(modified_input).unsqueeze(0).unsqueeze(1).float()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():  # Gradiensek számításának kikapcsolása\n",
    "        output = model(modified_input)  # Modell alkalmazása\n",
    "        pred_prob = output.squeeze().numpy()  # Valószínűségek kinyerése\n",
    "        pred_labels = 1 if pred_prob >= 0.5 else 0\n",
    "\n",
    "    print(f\"Predicted label: {convert_label(pred_labels)}, Prob: {pred_prob}\")\n",
    "    print(\"True label: \", convert_label(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffix percentage: 0.05, Attack Accuracy: 12.24%, Mask size: 703\n",
      "Suffix percentage: 0.1, Attack Accuracy: 10.20%, Mask size: 1367\n",
      "Suffix percentage: 0.15, Attack Accuracy: 20.41%, Mask size: 1975\n",
      "Suffix percentage: 0.2, Attack Accuracy: 16.33%, Mask size: 2524\n"
     ]
    }
   ],
   "source": [
    "suffix_percentages = [.05, .1, .15, .2]\n",
    "\n",
    "def calculate_attack_accuracy(suffix_percentage):\n",
    "    model.eval()  # Teszt módba állítjuk a modellt\n",
    "    predictions, true_labels = [], []\n",
    "    mask_sizes = []\n",
    "    model.to('cpu')\n",
    "\n",
    "    for malware_file in malware_files:\n",
    "        binary = torch.tensor(malware_file).squeeze()\n",
    "        suffix_length = int(binary.shape[0] * suffix_percentage)\n",
    "        \n",
    "        # Kezdetben nullákat fűzünk hozzá\n",
    "        suffix_zeros = torch.zeros(suffix_length, dtype=data.dtype)\n",
    "        modified_data = torch.cat((binary, suffix_zeros), dim=0)\n",
    "\n",
    "        # Eredeti preprocess-t végighatjuk\n",
    "        modified_input = preprocess_binary_file(modified_data, 2**14)\n",
    "\n",
    "        # Most meghatározzuk, mely pozíciók módosíthatóak, az eredeti bináris fájl alapján\n",
    "        modifiable_positions, M_len = determine_modifiable_positions(binary, s, suffix_length)\n",
    "        mask_sizes.append(M_len)\n",
    "\n",
    "        # Módosítjuk a megfelelő pozíciókat (ahol csak a adversarial suffix van)\n",
    "        for pos in modifiable_positions:\n",
    "            modified_input[pos] = torch.rand(1)  # Random érték [0, 1] között\n",
    "\n",
    "        # Az inputot megfelelő formátumra alakítjuk\n",
    "        modified_input = torch.tensor(modified_input).unsqueeze(0).unsqueeze(1).float()\n",
    "        \n",
    "        with torch.no_grad():  \n",
    "            output = model(modified_input)  \n",
    "            pred_prob = output.squeeze().numpy()  \n",
    "            predictions.append(pred_prob)\n",
    "            true_labels.append(1)\n",
    "\n",
    "    # Bináris osztályozási döntések (0.5 küszöbértékkel)\n",
    "    pred_labels = [1 if p >= 0.5 else 0 for p in predictions]\n",
    "\n",
    "    # Attack accuracy és mask size kiszámítása\n",
    "    attack_acc = (np.array(pred_labels) != np.array(true_labels)).mean()\n",
    "    mask_size = np.mean(mask_sizes)\n",
    "    return attack_acc, mask_size\n",
    "\n",
    "for suffix_percentage in suffix_percentages:\n",
    "    attack_acc, mask_size = calculate_attack_accuracy(suffix_percentage)\n",
    "    print(f\"Suffix percentage: {suffix_percentage}, Attack Accuracy: {attack_acc*100:.2f}%, Mask size: {mask_size:.0f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 feladat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ismerjük a modell paramétereit, és kitudjuk számolni a gradienseket\n",
    "# PGD\n",
    "# x[M] := maszkra szűrt x\n",
    "# x^t+1[M] = Π[0,1](x^t[M] − ε ⋅ sign(∇x^t[M]lossf(θ, x^t, ytarget)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_attack(model, x, y, epsilon, alpha, num_iter, indices_modifiable):\n",
    "    \"\"\"Projected Gradient Descent támadás.\n",
    "    \n",
    "    Args:\n",
    "        model: A támadott modell.\n",
    "        x: A bemeneti adatok tensora.\n",
    "        y: A cél tensor (a helyes címkék).\n",
    "        epsilon: A támadás erőssége.\n",
    "        alpha: Lépésköz minden iterációban.\n",
    "        num_iter: Az iterációk száma.\n",
    "        indices_modifiable: A módosítható pozíciók listája vagy tensora.\n",
    "    \n",
    "    Returns:\n",
    "        A módosított bemeneti adatok tensora.\n",
    "    \"\"\"\n",
    "    # Az eredeti adat másolata, amelyet módosítani fogunk\n",
    "    x_adv = x.clone().detach().requires_grad_(True)\n",
    "\n",
    "     # A batch és a channel dimenziók figyelembevétele\n",
    "    indices = torch.zeros_like(x_adv, dtype=torch.bool)  # Először minden értéket False-ra állítunk\n",
    "    indices[:, :, indices_modifiable] = True  # Csak a módosítható pozíciókat állítjuk True-ra\n",
    "\n",
    "    \n",
    "    # Iterációk végrehajtása\n",
    "    for i in range(num_iter):\n",
    "        outputs = model(x_adv)\n",
    "        model.zero_grad()  # Nullázzuk a gradienseket a modellben\n",
    "        loss = torch.nn.functional.cross_entropy(outputs, y)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Itt a gradiens jele alapján frissítjük az értékeket, de csak a kijelölt True pozíciókon\n",
    "            x_adv_grad = x_adv.grad.sign()\n",
    "            x_adv[indices] += alpha * x_adv_grad[indices]\n",
    "            x_adv = torch.clamp(x_adv, 0, 1)  # Korlátozzuk az értékeket az [0,1] tartományra\n",
    "            # Az x_adv-nak a ε távolságon belül kell maradnia az eredeti x-től\n",
    "            x_adv = torch.min(torch.max(x_adv, x - epsilon), x + epsilon)\n",
    "            x_adv.detach_().requires_grad_(True)  # Leválasztjuk a gradiens számítást, majd újraindítjuk\n",
    "\n",
    "    \n",
    "    return x_adv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffix percentage: 0.05, Attack Accuracy: 0.00%\n",
      "Suffix percentage: 0.1, Attack Accuracy: 0.00%\n",
      "Suffix percentage: 0.15, Attack Accuracy: 4.08%\n",
      "Suffix percentage: 0.2, Attack Accuracy: 8.16%\n"
     ]
    }
   ],
   "source": [
    "def calculate_pgd_accuracy(suffix_percentage):\n",
    "\n",
    "    epsilon = 0.3  # A támadás maximális mértéke (0.03)\n",
    "    alpha = 0.1  # A támadás lépésköze\n",
    "    num_iter = 40  # Az iterációk száma\n",
    "    predictions, true_labels = [], []\n",
    "\n",
    "    for malware_file in malware_files:\n",
    "        binary = torch.tensor(malware_file).squeeze()\n",
    "        suffix_length = int(binary.shape[0] * suffix_percentage)\n",
    "\n",
    "        # Kezdetben nullákat fűzünk hozzá\n",
    "        suffix_zeros = torch.zeros(suffix_length, dtype=data.dtype)\n",
    "        modified_data = torch.cat((binary, suffix_zeros), dim=0)\n",
    "        modifiable_positions, M_len = determine_modifiable_positions(binary, s, suffix_length)\n",
    "\n",
    "        modified_input = preprocess_binary_file(modified_data, s)\n",
    "        x = torch.tensor(modified_input).unsqueeze(0).unsqueeze(1).float()\n",
    "        y = torch.tensor([1]).unsqueeze(0).float()\n",
    "\n",
    "        # A PGD támadás végrehajtása\n",
    "        x_adv = pgd_attack(model, x, y, epsilon, alpha, num_iter, list(modifiable_positions))\n",
    "\n",
    "        with torch.no_grad():  \n",
    "            output = model(x_adv)  \n",
    "            pred_prob = output.squeeze().numpy()  \n",
    "            predictions.append(pred_prob)\n",
    "            true_labels.append(1)\n",
    "\n",
    "    # Bináris osztályozási döntések (0.5 küszöbértékkel)\n",
    "    pred_labels = [1 if p >= 0.5 else 0 for p in predictions]\n",
    "\n",
    "    # Attack accuracy és mask size kiszámítása\n",
    "    attack_acc = (np.array(pred_labels) != np.array(true_labels)).mean()\n",
    "    \n",
    "    return attack_acc\n",
    "    \n",
    "for suffix_percentage in suffix_percentages:\n",
    "    attack_acc = calculate_pgd_accuracy(suffix_percentage)\n",
    "    print(f\"Suffix percentage: {suffix_percentage}, Attack Accuracy: {attack_acc*100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
