{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'ml_sec_hw_data/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_binary_loader(bytes, s):\n",
    "    l = len(bytes)\n",
    "    print(\"bytes length: \", l)\n",
    "\n",
    "    if l == s:\n",
    "        # Ha a fájl mérete pontosan s\n",
    "        x = bytes\n",
    "    elif l < s:\n",
    "        # Ha a fájl mérete kisebb mint s, hozzáadunk nullás paddingot\n",
    "        x = np.pad(bytes, (0, s - l), 'constant', constant_values=(0,))\n",
    "    else:\n",
    "        # Ha a fájl mérete nagyobb mint s, átlagoljuk a bájtokat\n",
    "        group_size = np.ceil(l / s) # csoportok számának kiszámítása\n",
    "        print(\"group size: \", group_size)\n",
    "        # Először hozzáadunk szükséges paddingot\n",
    "        padding_length = s * group_size - l \n",
    "        print(\"padding length: \", padding_length)\n",
    "        padded_bytes = np.pad(bytes, (0, int(padding_length)), 'constant', constant_values=(0,))\n",
    "        print(\"padding bytes: \", padded_bytes)\n",
    "        # Átlagolás\n",
    "        reshaped_bytes = padded_bytes.reshape(-1, int(group_size))\n",
    "        print(\"reshaped bytes: \\n\", reshaped_bytes)\n",
    "        x = np.mean(reshaped_bytes, axis=1)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group size:  2.0\n",
      "padding length:  2.0\n",
      "padding bytes:  [1 2 3 4 0 0]\n",
      "reshaped bytes:  [[1 2]\n",
      " [3 4]\n",
      " [0 0]]\n",
      "(3,)\n",
      "[1.5 3.5 0. ]\n"
     ]
    }
   ],
   "source": [
    "x = test_binary_loader([1,2,3,4], 3)\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5000, 3.5000, 0.0000], dtype=torch.float64)\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor_x = torch.tensor(x)\n",
    "print(tensor_x)\n",
    "\n",
    "tensor_x = tensor_x.unsqueeze(0)\n",
    "print(tensor_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(label):\n",
    "    return 'malware' if label == 1 else 'benign'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalwareDataset(Dataset):\n",
    "    def __init__(self, data_folder, s=2**14):\n",
    "        self.data_folder = data_folder\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        for label in os.listdir(data_folder): # data/.../train -> malware, benign\n",
    "            for file in os.listdir(os.path.join(data_folder, label)):\n",
    "                file_path = os.path.join(data_folder, label, file)\n",
    "                x = self.preprocess_binary_file(file_path, s)\n",
    "                self.data.append(x)\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def preprocess_binary_file(self, file_path, s):\n",
    "        # Bináris fájl beolvasása\n",
    "        with open(file_path, 'rb') as file:\n",
    "            file_bytes = np.fromfile(file, dtype=np.uint8)\n",
    "\n",
    "        l = len(file_bytes)\n",
    "\n",
    "        if l == s:\n",
    "            # Ha a fájl mérete pontosan s\n",
    "            x = file_bytes\n",
    "        elif l < s:\n",
    "            # Ha a fájl mérete kisebb mint s, hozzáadunk nullás paddingot\n",
    "            x = np.pad(file_bytes, (0, s - l), 'constant', constant_values=(0,))\n",
    "        else:\n",
    "            # Ha a fájl mérete nagyobb mint s, átlagoljuk a bájtokat\n",
    "            # Először hozzáadunk szükséges paddingot\n",
    "            padding_length = s * np.ceil(l / s) - l\n",
    "            padded_bytes = np.pad(file_bytes, (0, int(padding_length)), 'constant', constant_values=(0,))\n",
    "            # Átlagolás\n",
    "            x = np.mean(padded_bytes.reshape(-1, int(np.ceil(l / s))), axis=1)\n",
    "\n",
    "        # Normalizálás [0, 1] tartományba\n",
    "        x_normalized = x / 255\n",
    "\n",
    "        return x_normalized\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx]), torch.tensor([1 if self.labels[idx] == 'malware' else 0])\n",
    "    \n",
    "def get_loader(data_folder, batch_size=32):\n",
    "    dataset = MalwareDataset(data_folder)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loader(os.path.join(data_folder, 'train'), 32)\n",
    "test_loader = get_loader(os.path.join(data_folder, 'test'), 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 16384])\n",
      "torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "data, label = next(iter(train_loader))\n",
    "print(data.unsqueeze(1).float().shape)\n",
    "print(label.float().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalwareDetector(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 16, kernel_size=10, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "        )\n",
    "        self.linear = nn.Linear(in_features=130976, out_features=1, bias=True)\n",
    "        self.out = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = x.view(x.size(0), -1) # Flatten\n",
    "        x = self.linear(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.1271088421344757\n",
      "Epoch 2/10, Loss: 0.0075139193795621395\n",
      "Epoch 3/10, Loss: 0.004727795720100403\n",
      "Epoch 4/10, Loss: 0.005919822491705418\n",
      "Epoch 5/10, Loss: 0.028740501031279564\n",
      "Epoch 6/10, Loss: 0.002325571607798338\n",
      "Epoch 7/10, Loss: 0.0006117887678556144\n",
      "Epoch 8/10, Loss: 0.0008404992404393852\n",
      "Epoch 9/10, Loss: 0.0007017732714302838\n",
      "Epoch 10/10, Loss: 0.0009823349537327886\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MalwareDetector().to(device)\n",
    "bce = nn.BCELoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model.to(device)\n",
    "\n",
    "def train(model, train_loader, opt, loss_fn, epochs=10):\n",
    "    for epoch in range(epochs):\n",
    "        for data, labels in train_loader:\n",
    "            data = data.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            out = model(data.unsqueeze(1).float())\n",
    "            loss = loss_fn(out, labels.float())\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')\n",
    "\n",
    "train(model, train_loader, opt, bce, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9974358974358974\n",
      "TPR: 0.9948717948717949\n",
      "TNR: 1.0\n",
      "FPR: 0.0\n",
      "FNR: 0.005128205128205128\n",
      "AUC: 0.9993951347797502\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "\n",
    "def test_model(model, test_loader):\n",
    "    model.eval()  # Teszt módba állítjuk a modellt\n",
    "    predictions, true_labels = [], []\n",
    "    model.to('cpu')\n",
    "    with torch.no_grad():  # Gradiensek számításának kikapcsolása\n",
    "        for data, labels in test_loader:\n",
    "            output = model(data.unsqueeze(1).float())  # Modell alkalmazása\n",
    "            pred_prob = output.squeeze().numpy()  # Valószínűségek kinyerése\n",
    "            predictions.extend(pred_prob)\n",
    "            true_labels.extend(labels.numpy())\n",
    "    \n",
    "    # Bináris osztályozási döntések (0.5 küszöbértékkel)\n",
    "    pred_labels = [1 if p >= 0.5 else 0 for p in predictions]\n",
    "    \n",
    "    # Metrikák kiszámítása\n",
    "    auc_score = roc_auc_score(true_labels, predictions)\n",
    "    tn, fp, fn, tp = confusion_matrix(true_labels, pred_labels).ravel()\n",
    "    \n",
    "    tpr = tp / (tp + fn)  # True Positive Rate\n",
    "    tnr = tn / (tn + fp)  # True Negative Rate\n",
    "    fpr = fp / (tn + fp)  # False Positive Rate\n",
    "    fnr = fn / (tp + fn)  # False Negative Rate\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)  # Átlagos pontosság\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"TPR: {tpr}\")\n",
    "    print(f\"TNR: {tnr}\")\n",
    "    print(f\"FPR: {fpr}\")\n",
    "    print(f\"FNR: {fnr}\")\n",
    "    print(f\"AUC: {auc_score}\")\n",
    "    \n",
    "    return accuracy, tpr, tnr, fpr, fnr, auc_score\n",
    "\n",
    "\n",
    "accuracy, tpr, tnr, fpr, fnr, auc = test_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kérdések:\n",
    "1. Mi a betanított modell átlagos pontossága a teszt adaton ha s = 2\n",
    "14? : 99.48%\n",
    "2. Mi a modell TPR, TNR, FPR, FNR, valamint AUC értéke a teszt adaton? Mi állapítható meg ezekből a modell\n",
    "teljesítményéről? : Magas pontosság, nagyon ritkán téveszt a detektorunk. Felismeri mind a malware-t mind a benign-t. Szinte nincs félreosztályzás\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adv_bytes:  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 0, 0, 0, 0]\n",
      "bytes length:  15\n",
      "group size:  3.0\n",
      "padding length:  3.0\n",
      "padding bytes:  [ 1  2  3  4  5  6  7  8  9 10  0  0  0  0  0  0  0  0]\n",
      "reshaped bytes: \n",
      " [[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10  0  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "input:  [2.         5.         8.         3.33333333 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "original_bytes = [1,2,3,4,5,6,7,8,9,10]\n",
    "adv_suffix = [0] * 5 # ha egy csoport csakis suffix-t tartalmaz akkor a tömörített verzióban is azok lesznek, azaz módosítani tudjuk őket.\n",
    "adv_bytes = original_bytes + adv_suffix\n",
    "print(\"adv_bytes: \", adv_bytes)\n",
    "x = test_binary_loader(adv_bytes, 6)\n",
    "print(\"input: \", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytes length:  14\n",
      "original bytes lenght:  10\n",
      "group size:  3\n",
      "original groups:  4\n",
      "padding length:  4\n",
      "padding bytes:  [ 1  2  3  4  5  6  7  8  9 10  0  0  0  0  0  0  0  0]\n",
      "reshaped bytes: \n",
      " [[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10  0  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "padding groups:  2\n",
      "total groups:  6\n",
      "Binary length: 14, 's' value: 6, modifiable positions: set()\n",
      "bytes length:  15\n",
      "original bytes lenght:  10\n",
      "group size:  3\n",
      "original groups:  4\n",
      "padding length:  3\n",
      "padding bytes:  [ 1  2  3  4  5  6  7  8  9 10  0  0  0  0  0  0  0  0]\n",
      "reshaped bytes: \n",
      " [[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10  0  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "padding groups:  1\n",
      "total groups:  6\n",
      "5\n",
      "Binary length: 15, 's' value: 6, modifiable positions: {5}\n"
     ]
    }
   ],
   "source": [
    "def test_determine_modifiable_positions(bytes, s, suffix_length):\n",
    "    l = len(bytes)\n",
    "    modifiable_positions = set()\n",
    "    original_bytes_lenght = l-suffix_length\n",
    "    print(\"bytes length: \", l)\n",
    "    print(\"original bytes lenght: \", original_bytes_lenght)\n",
    "\n",
    "    if l >= s:\n",
    "        # Számítjuk, hány bájt kerül átlagolásra egy vektor elem létrehozásához\n",
    "        group_size = int(np.ceil(l / s))\n",
    "        \n",
    "        print(\"group size: \", group_size)\n",
    "       \n",
    "\n",
    "        # mennyi group kell az eredeti fájlhoz\n",
    "        original_groups = int(np.ceil(original_bytes_lenght / group_size))\n",
    "        print(\"original groups: \", original_groups) \n",
    "\n",
    "        # Meghatározzuk, hány bájt kerül hozzáadásra paddingként\n",
    "        padding_length = int(s * group_size - l)\n",
    "        print(\"padding length: \", padding_length)\n",
    "\n",
    "        padded_bytes = np.pad(bytes, (0, padding_length), 'constant', constant_values=(0,))\n",
    "        print(\"padding bytes: \", padded_bytes)\n",
    "        \n",
    "        reshaped_bytes = padded_bytes.reshape(-1, group_size)\n",
    "        \n",
    "        # Csoportok tartalmazhatnak: (ha márcsak egy másmilyen elem is van mint suffix, akkor az egész csoport nem módosítható)\n",
    "            # eredeti fájl csoportok\n",
    "            # (tiszta) suffix csoportok\n",
    "            # padding csoportok\n",
    "        \n",
    "        print(\"reshaped bytes: \\n\", reshaped_bytes)\n",
    "\n",
    "        # mennyi group kell az eredeti fájlhoz\n",
    "        padding_groups = int(np.ceil(padding_length / group_size))\n",
    "        print(\"padding groups: \", padding_groups) \n",
    "\n",
    "        total_length = l+padding_length\n",
    "        total_groups = int(np.ceil(total_length / group_size))\n",
    "        print(\"total groups: \", total_groups)\n",
    "\n",
    "        for i in range(original_groups+1, total_groups-padding_groups+1):\n",
    "            print(i)\n",
    "            modifiable_positions.add(i)\n",
    "\n",
    "        # # Ha a suffix hossza nagyobb, mint a szükséges padding hossza, az utolsó csoportba eső bájtok módosíthatók\n",
    "        # if suffix_length > padding_length:\n",
    "        #     modifiable_positions.add(s - 1)  # Az utolsó vektor pozíció módosítható\n",
    "    \n",
    "    return modifiable_positions\n",
    "\n",
    "# Tesztesetek a függvény ellenőrzésére\n",
    "# Példa bináris fájlok és az 's' paraméter\n",
    "binaries = [\n",
    "    ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10] + [0]*4, 6, 4),  # 4 bájt hozzáadva\n",
    "    ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10] + [0]*5, 6, 5)   # 5 bájt hozzáadva\n",
    "]\n",
    "\n",
    "# A determine_modifiable_positions függvény tesztelése\n",
    "for binary, s, suffix in binaries:\n",
    "    modifiable_positions = test_determine_modifiable_positions(np.array(binary), s, suffix)\n",
    "    print(f\"Binary length: {len(binary)}, 's' value: {s}, modifiable positions: {modifiable_positions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def determine_modifiable_positions(binary_tensor, s, suffix_length):\n",
    "    modifiable_positions = set()\n",
    "\n",
    "    # Original binary length\n",
    "    original_binary_length = binary_tensor.shape[0]\n",
    "\n",
    "    # Attach suffix to binary\n",
    "    suffix_tensor = torch.zeros(suffix_length, dtype=binary_tensor.dtype)\n",
    "    binary_suffix = torch.cat((binary_tensor, suffix_tensor), dim=0)\n",
    "\n",
    "    l = binary_suffix.shape[0]\n",
    "    \n",
    "    if l >= s:\n",
    "        group_size = int(np.ceil(l / s))\n",
    "        \n",
    "        # How many groups are needed for the original file\n",
    "        original_groups = int(np.ceil(original_binary_length / group_size))\n",
    "\n",
    "        # Calculate the padding length needed\n",
    "        padding_length = int(s * group_size - l)\n",
    "        \n",
    "        # How many groups are needed for the padding\n",
    "        padding_groups = int(np.ceil(padding_length / group_size))\n",
    "    \n",
    "        total_length = l + padding_length\n",
    "        total_groups = int(np.ceil(total_length / group_size))\n",
    "        \n",
    "        # Identify modifiable groups\n",
    "        for i in range(original_groups + 1, total_groups - padding_groups + 1):\n",
    "            modifiable_positions.add(i)\n",
    "    \n",
    "    return modifiable_positions, len(modifiable_positions), binary_suffix\n",
    "\n",
    "# # Example Usage:\n",
    "# data = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=torch.float32)  # Example binary data tensor\n",
    "# s = 6  # Target vector length\n",
    "# suffix_length = 5  # Suffix length\n",
    "\n",
    "# modifiable_positions, num_modifiable_positions, modified_data = determine_modifiable_positions(data, s, suffix_length)\n",
    "# print(f\"Modifiable positions: {modifiable_positions}, \\nNumber of modifiable positions: {num_modifiable_positions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16384])\n"
     ]
    }
   ],
   "source": [
    "victim_loader = get_loader(os.path.join(data_folder, 'victim'), 1)\n",
    "data, label = next(iter(victim_loader))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "attackable_files = []\n",
    "victim_malware_path = 'ml_sec_hw_data/data/victim/malware'\n",
    "for file in os.listdir(victim_malware_path):\n",
    "    file_path = os.path.join(victim_malware_path, file)\n",
    "    with open(file_path, 'rb') as file:\n",
    "        file_bytes = np.fromfile(file, dtype=np.uint8)\n",
    "        if len(file_bytes) >= 2**14:\n",
    "            attackable_files.append(file_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51696,)\n"
     ]
    }
   ],
   "source": [
    "test_malware = attackable_files[0]\n",
    "print(test_malware.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_binary_filefile_path(file_bytes, s):\n",
    "    l = len(file_bytes)\n",
    "    padding_length = s * np.ceil(l / s) - l\n",
    "    padded_bytes = np.pad(file_bytes, (0, int(padding_length)), 'constant', constant_values=(0,))\n",
    "    x = np.mean(padded_bytes.reshape(-1, int(np.ceil(l / s))), axis=1)\n",
    "    x_normalized = x / 255\n",
    "\n",
    "    return x_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n"
     ]
    }
   ],
   "source": [
    "test_input = preprocess_binary_filefile_path(test_malware, 2**14)\n",
    "test_input = torch.tensor(test_input)\n",
    "print(test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test_input.unsqueeze(0).unsqueeze(1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 16384])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: malware, Prob: 0.9996621608734131\n",
      "True label:  malware\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():  # Gradiensek számításának kikapcsolása\n",
    "    output = model(test_input)  # Modell alkalmazása\n",
    "    pred_prob = output.squeeze().numpy()  # Valószínűségek kinyerése\n",
    "    pred_labels = 1 if pred_prob >= 0.5 else 0\n",
    "\n",
    "print(f\"Predicted label: {convert_label(pred_labels)}, Prob: {pred_prob}\")\n",
    "print(\"True label: \", convert_label(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{12925, 12926, 12927, 12928, 12929, 12930, 12931, 12932, 12933, 12934, 12935, 12936, 12937, 12938, 12939, 12940, 12941, 12942, 12943, 12944, 12945, 12946, 12947, 12948, 12949, 12950, 12951, 12952, 12953, 12954, 12955, 12956, 12957, 12958, 12959, 12960, 12961, 12962, 12963, 12964, 12965, 12966, 12967, 12968, 12969, 12970, 12971, 12972, 12973, 12974, 12975, 12976, 12977, 12978, 12979, 12980, 12981, 12982, 12983, 12984, 12985, 12986, 12987, 12988, 12989, 12990, 12991, 12992, 12993, 12994, 12995, 12996, 12997, 12998, 12999, 13000, 13001, 13002, 13003, 13004, 13005, 13006, 13007, 13008, 13009, 13010, 13011, 13012, 13013, 13014, 13015, 13016, 13017, 13018, 13019, 13020, 13021, 13022, 13023, 13024, 13025, 13026, 13027, 13028, 13029, 13030, 13031, 13032, 13033, 13034, 13035, 13036, 13037, 13038, 13039, 13040, 13041, 13042, 13043, 13044, 13045, 13046, 13047, 13048, 13049, 13050, 13051, 13052, 13053, 13054, 13055, 13056, 13057, 13058, 13059, 13060, 13061, 13062, 13063, 13064, 13065, 13066, 13067, 13068, 13069, 13070, 13071, 13072, 13073, 13074, 13075, 13076, 13077, 13078, 13079, 13080, 13081, 13082, 13083, 13084, 13085, 13086, 13087, 13088, 13089, 13090, 13091, 13092, 13093, 13094, 13095, 13096, 13097, 13098, 13099, 13100, 13101, 13102, 13103, 13104, 13105, 13106, 13107, 13108, 13109, 13110, 13111, 13112, 13113, 13114, 13115, 13116, 13117, 13118, 13119, 13120, 13121, 13122, 13123, 13124, 13125, 13126, 13127, 13128, 13129, 13130, 13131, 13132, 13133, 13134, 13135, 13136, 13137, 13138, 13139, 13140, 13141, 13142, 13143, 13144, 13145, 13146, 13147, 13148, 13149, 13150, 13151, 13152, 13153, 13154, 13155, 13156, 13157, 13158, 13159, 13160, 13161, 13162, 13163, 13164, 13165, 13166, 13167, 13168, 13169, 13170, 13171, 13172, 13173, 13174, 13175, 13176, 13177, 13178, 13179, 13180, 13181, 13182, 13183, 13184, 13185, 13186, 13187, 13188, 13189, 13190, 13191, 13192, 13193, 13194, 13195, 13196, 13197, 13198, 13199, 13200, 13201, 13202, 13203, 13204, 13205, 13206, 13207, 13208, 13209, 13210, 13211, 13212, 13213, 13214, 13215, 13216, 13217, 13218, 13219, 13220, 13221, 13222, 13223, 13224, 13225, 13226, 13227, 13228, 13229, 13230, 13231, 13232, 13233, 13234, 13235, 13236, 13237, 13238, 13239, 13240, 13241, 13242, 13243, 13244, 13245, 13246, 13247, 13248, 13249, 13250, 13251, 13252, 13253, 13254, 13255, 13256, 13257, 13258, 13259, 13260, 13261, 13262, 13263, 13264, 13265, 13266, 13267, 13268, 13269, 13270, 13271, 13272, 13273, 13274, 13275, 13276, 13277, 13278, 13279, 13280, 13281, 13282, 13283, 13284, 13285, 13286, 13287, 13288, 13289, 13290, 13291, 13292, 13293, 13294, 13295, 13296, 13297, 13298, 13299, 13300, 13301, 13302, 13303, 13304, 13305, 13306, 13307, 13308, 13309, 13310, 13311, 13312, 13313, 13314, 13315, 13316, 13317, 13318, 13319, 13320, 13321, 13322, 13323, 13324, 13325, 13326, 13327, 13328, 13329, 13330, 13331, 13332, 13333, 13334, 13335, 13336, 13337, 13338, 13339, 13340, 13341, 13342, 13343, 13344, 13345, 13346, 13347, 13348, 13349, 13350, 13351, 13352, 13353, 13354, 13355, 13356, 13357, 13358, 13359, 13360, 13361, 13362, 13363, 13364, 13365, 13366, 13367, 13368, 13369, 13370, 13371, 13372, 13373, 13374, 13375, 13376, 13377, 13378, 13379, 13380, 13381, 13382, 13383, 13384, 13385, 13386, 13387, 13388, 13389, 13390, 13391, 13392, 13393, 13394, 13395, 13396, 13397, 13398, 13399, 13400, 13401, 13402, 13403, 13404, 13405, 13406, 13407, 13408, 13409, 13410, 13411, 13412, 13413, 13414, 13415, 13416, 13417, 13418, 13419, 13420, 13421, 13422, 13423, 13424, 13425, 13426, 13427, 13428, 13429, 13430, 13431, 13432, 13433, 13434, 13435, 13436, 13437, 13438, 13439, 13440, 13441, 13442, 13443, 13444, 13445, 13446, 13447, 13448, 13449, 13450, 13451, 13452, 13453, 13454, 13455, 13456, 13457, 13458, 13459, 13460, 13461, 13462, 13463, 13464, 13465, 13466, 13467, 13468, 13469, 13470, 13471, 13472, 13473, 13474, 13475, 13476, 13477, 13478, 13479, 13480, 13481, 13482, 13483, 13484, 13485, 13486, 13487, 13488, 13489, 13490, 13491, 13492, 13493, 13494, 13495, 13496, 13497, 13498, 13499, 13500, 13501, 13502, 13503, 13504, 13505, 13506, 13507, 13508, 13509, 13510, 13511, 13512, 13513, 13514, 13515, 13516, 13517, 13518, 13519, 13520, 13521, 13522, 13523, 13524, 13525, 13526, 13527, 13528, 13529, 13530, 13531, 13532, 13533, 13534, 13535, 13536, 13537, 13538, 13539, 13540, 13541, 13542, 13543, 13544, 13545, 13546, 13547, 13548, 13549, 13550, 13551, 13552, 13553, 13554, 13555, 13556, 13557, 13558, 13559, 13560, 13561, 13562, 13563, 13564, 13565, 13566, 13567, 13568, 13569, 13570}\n",
      "646\n"
     ]
    }
   ],
   "source": [
    "binary = torch.tensor(test_malware).squeeze()\n",
    "s = 2**14  \n",
    "suffix_percentage = 0.05  \n",
    "\n",
    "suffix_length = int(binary.shape[0] * suffix_percentage)\n",
    "# Kezdetben nullákat fűzünk hozzá\n",
    "# suffix_zeros = torch.zeros(suffix_length, dtype=data.dtype)\n",
    "# modified_data = torch.cat((data, suffix_zeros), dim=0)\n",
    "\n",
    "# Most meghatározzuk, mely pozíciók módosíthatóak\n",
    "# Ebben a példában feltételezzük, hogy ezeket a pozíciókat előzőleg már meghatároztuk.\n",
    "modifiable_positions, M_len, modified_data = determine_modifiable_positions(binary, s, suffix_length)\n",
    "\n",
    "print(modifiable_positions)\n",
    "print(M_len)\n",
    "\n",
    "# Most random értékeket helyezünk a módosítható pozíciókra\n",
    "for pos in modifiable_positions:\n",
    "    # Itt egy konkrét módosítási logikát kellene implementálni, például:\n",
    "    # Ha a 'modifiable_positions' valódi indexeket tartalmaz, használhatunk egy egyszerű hozzárendelést\n",
    "    # Ebben a példában egyszerűség kedvéért feltételezzük, hogy az 'modifiable_positions' tartalmazza az indexeket közvetlenül\n",
    "    modified_data[pos] = torch.rand(1)  # Random érték [0, 1] között\n",
    "\n",
    "# Itt folytatódik a modell kiértékelése a módosított adatokkal, hasonlóan az előző példádhoz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51696])\n",
      "torch.Size([54280])\n"
     ]
    }
   ],
   "source": [
    "print(binary.shape)\n",
    "print(modified_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n"
     ]
    }
   ],
   "source": [
    "modified_test_input = preprocess_binary_filefile_path(modified_data, 2**14)\n",
    "modified_test_input = torch.tensor(modified_test_input)\n",
    "print(modified_test_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: malware, Prob: 0.9997403025627136\n",
      "True label:  malware\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():  # Gradiensek számításának kikapcsolása\n",
    "    output = model(modified_test_input.unsqueeze(0).unsqueeze(1).float())  # Modell alkalmazása\n",
    "    pred_prob = output.squeeze().numpy()  # Valószínűségek kinyerése\n",
    "    pred_labels = 1 if pred_prob >= 0.5 else 0\n",
    "\n",
    "print(f\"Predicted label: {convert_label(pred_labels)}, Prob: {pred_prob}\")\n",
    "print(\"True label: \", convert_label(1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
